FROM ubuntu:20.04
# Initial installations (run in same line to avoid caching issues)
ARG DEBIAN_FRONTEND="noninteractive"
ENV TZ="SE"
RUN apt-get update && apt-get install --no-install-recommends --yes sudo openssh-server \
    pdsh \
    openjdk-8-jre-headless \
    build-essential \
    python3.8 \
    python3-pip \
    python3-dev \
    scala \
    wget && rm -rf /var/lib/apt/lists/*

# Hadoop installation
ENV JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64/jre"
RUN wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz && \
    tar -xvf hadoop-3.3.0.tar.gz && \
    mv hadoop-3.3.0/ /usr/local/hadoop && \
    rm hadoop-3.3.0.tar.gz
ENV HADOOP_HOME="/usr/local/hadoop"
ENV PATH="${PATH}:$HADOOP_HOME/bin"
ENV PATH="${PATH}:$HADOOP_HOME/sbin"
ENV HADOOP_MAPRED_HOME="${HADOOP_HOME}"
ENV HADOOP_COMMON_HOME="${HADOOP_HOME}"
ENV HADOOP_HDFS_HOME="${HADOOP_HOME}"
ENV YARN_HOME="${HADOOP_HOME}"

# Spark installation
RUN wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz && \
    tar xvf spark-3.2.0-bin-hadoop3.2.tgz && \
    mv spark-3.2.0-bin-hadoop3.2/ /usr/local/spark && \
    rm spark-3.2.0-bin-hadoop3.2.tgz
ENV PATH="${PATH}:$SPARK_HOME/bin"
ENV SPARK_HOME="/usr/local/spark"
ENV SPARK_NO_DAEMONIZE="true"
